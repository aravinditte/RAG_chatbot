# RAG_chatbot
This project implements a Retrieval-Augmented Generation (RAG) chatbot using Python and LangChain. The chatbot leverages external data sources to provide accurate and context-aware responses to user queries.

# Project Structure
```bash
ğŸ“ RAG_Chatbot
â”‚â”€â”€ ğŸ“ models/                   # Folder to store local LLM models (optional)
â”‚â”€â”€ ğŸ“ data/                     # Dataset storage
â”‚â”€â”€ ğŸ“ modules/                  # Modularized Python scripts
â”‚â”€â”€ ğŸ“ scripts/                  # Additional scripts (optional)
â”‚â”€â”€ ğŸ“ notebooks/                # Jupyter notebooks (optional)
â”‚â”€â”€ chatbot.py                   # Main Streamlit chatbot script
â”‚â”€â”€ retriever.py                  # Document retrieval logic
â”‚â”€â”€ rag_pipeline.py               # RAG pipeline setup with embeddings
â”‚â”€â”€ requirements.txt              # Python dependencies
â”‚â”€â”€ README.md                     # Documentation
â”‚â”€â”€ chatbot_responses.csv         # Sample chatbot responses (for submission)


1ï¸âƒ£ chatbot.py (Main Streamlit App)
    Handles user interaction via Streamlit.
    Calls the retrieval pipeline for answering user queries.

2ï¸âƒ£ retriever.py (Retrieval Logic)
   Loads the retriever from ChromaDB.
   Embeds the query and retrieves relevant document chunks.

3ï¸âƒ£ rag_pipeline.py (Setting Up RAG)
   Loads dataset and creates embeddings.
   Uses FAISS or ChromaDB for retrieval.
   Can be run once to preprocess data.

4ï¸âƒ£ requirements.txt (Dependencies)
   Defines required Python libraries for deployment.

5ï¸âƒ£ README.md (Project Documentation)
   Installation Instructions
   How to Run the Chatbot
   How to Deploy on Streamlit Cloud

Refer Documentation for more information
